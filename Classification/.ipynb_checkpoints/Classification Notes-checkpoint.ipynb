{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Notes\n",
    "\n",
    "Here I'll work through my reasoning from choosing features to training a model on the data.\n",
    "\n",
    "Possible features:\n",
    "\n",
    "- crowLength\n",
    "- pathCrowRatio\n",
    "- coveredArea\n",
    "- windowArea\n",
    "- areaPerUnitL\n",
    "- areaPerUnitT\n",
    "- hurst\n",
    "- DFA\n",
    "- angleDensS\n",
    "- angleDensT\n",
    "- timeSpent\n",
    "- corrDim\n",
    "\n",
    "Possible labels:\n",
    "\n",
    "- transMode\n",
    "\n",
    "Could try and use some of the features as labels instead?\n",
    "\n",
    "Ideally I would put all of these into a table with each row representing a trajectory, this might be very large though - let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Metadata/Inventory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13395"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have roughly 13,400 trajectories, this is manageable. Now we need to write a script which will populate a csv with the features and labels for each trajectory. This may take a while.\n",
    "\n",
    "I've discarded the DFA feature because it was too buggy and I'm not sure how much it really adds.\n",
    "\n",
    "The featExtract script seems to be working nicely, giving me the csv I need. I've had to filter (arbitrarily) to trajectories with no fewer than 20 points, that are of 0.5mins < duration < 60mins and are longer than 20m. This was on one hand to remove the noisy short trajectories and also reduce computation time on the longer trajectories. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
